{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Agile Issue Generator\n",
    "\n",
    "This Python script is designed to help automate the creation and uploading of Agile issues, such as Epics, Stories, and Subtasks, to either Jira or Azure DevOps (DevOps). It generates a structured list of project tasks based on the provided project description, and you can customize the number of epics, stories, and subtasks to be generated.\n",
    "\n",
    "## Prerequisites\n",
    "\n",
    "Before using this script, ensure you have the following prerequisites:\n",
    "\n",
    "1. **Python**: You must have Python installed on your machine. You can download it from [python.org](https://www.python.org/downloads/).\n",
    "\n",
    "2. **Jira or Azure DevOps Account**: Depending on your choice, you should have an account and API access to either Jira or Azure DevOps.\n",
    "\n",
    "3. **API Key or Personal Access Token (PAT)**: You'll need an API key for Jira or a PAT for Azure DevOps for authentication.\n",
    "\n",
    "4. **Excel File**: If you're using Azure DevOps, you need an Excel file containing the issue data.\n",
    "\n",
    "## Setup\n",
    "\n",
    "1. Clone this repository or download the script.\n",
    "\n",
    "2. Open the script in your preferred code editor.\n",
    "\n",
    "3. Modify the script's variables to match your project's requirements:\n",
    "\n",
    "   ```python\n",
    "   num_epics = 1\n",
    "   num_stories = 6\n",
    "   num_subtasks = 0 # You can change this number as needed\n",
    "   project_name = \"\"\n",
    "   root_name = ''\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Required libraries and modules\n",
    "from dotenv import load_dotenv\n",
    "import pandas as pd\n",
    "import os\n",
    "import json\n",
    "import requests\n",
    "from requests.auth import HTTPBasicAuth\n",
    "import hashlib\n",
    "import openai\n",
    "from azure.devops.connection import Connection\n",
    "from azure.devops.v7_0.work_item_tracking.models import JsonPatchOperation, WorkItemRelation\n",
    "from msrest.authentication import BasicAuthentication\n",
    "\n",
    "# Configuration class to load environment variables\n",
    "class Config:\n",
    "    def __init__(self, path='./environment.env'):\n",
    "        # Load environment variables from specified file path\n",
    "        load_dotenv(dotenv_path=path)\n",
    "        # Jira API configurations\n",
    "        self.jira_id = os.getenv(\"JIRA_ID\")\n",
    "        self.jira_key = os.getenv(\"JIRA_KEY\")\n",
    "        # OpenAI API configurations\n",
    "        self.open_ai_endpoint = os.getenv(\"OPENAI_ENDPOINT\")\n",
    "        self.openai_key = os.getenv(\"OPENAI_KEY\")\n",
    "        self.chat_engine = os.getenv(\"CHAT_ENGINE\")\n",
    "\n",
    "# Class to handle Jira API operations\n",
    "class Jira():\n",
    "    def __init__(self, config):\n",
    "        # Initialize with Jira configurations\n",
    "        self.username = config.jira_id\n",
    "        self.api_token = config.jira_key\n",
    "        self.url = self.username.split('@')[0]\n",
    "\n",
    "    # Method to fetch projects from Jira\n",
    "    def fetch_projects(self, url):\n",
    "        response = requests.get(url, auth=HTTPBasicAuth(self.username, self.api_token))\n",
    "        return response.json() if response.status_code == 200 else None\n",
    "\n",
    "    # Method to retrieve issues for a specific project and issue type from Jira\n",
    "    def get_issues(self, project_key, project_name, issue_type):\n",
    "        url_issues = f\"https://{self.url}.atlassian.net/rest/api/3/search?jql=project={project_key} AND issuetype='{issue_type}'\"\n",
    "        response = requests.get(url_issues, auth=HTTPBasicAuth(self.username, self.api_token))\n",
    "        issues_json = []\n",
    "        if response.status_code == 200:\n",
    "            issues = response.json().get('issues', [])\n",
    "            for issue in issues:\n",
    "                issue_fields = issue['fields']\n",
    "                issue_name = issue_fields['summary']\n",
    "                description_content = issue_fields['description']\n",
    "                # Extract text from the issue's description content\n",
    "                description_texts = self.extract_text(description_content)\n",
    "                description_text = \" \".join(description_texts)\n",
    "                parent = issue_fields.get('parent', {}).get('fields', {}).get('summary') if issue_type != 'Epic' else None\n",
    "                current_hierarchy = f\"Parent: {parent}\" if parent else \"\" + f\" / Current: {issue_name}\"\n",
    "                issue_json = {\n",
    "                    \"project_name\": project_name,\n",
    "                    \"name\": issue_name,\n",
    "                    \"type\": issue_type,\n",
    "                    \"hierarchy\": current_hierarchy,\n",
    "                    \"description\": description_text\n",
    "                }\n",
    "                issues_json.append(issue_json)\n",
    "        return issues_json\n",
    "    \n",
    "    # New method to get all issue IDs for a given project\n",
    "    def get_all_issue_ids(self, project_key):\n",
    "        url_issues = f\"https://{self.url}.atlassian.net/rest/api/3/search?jql=project={project_key}\"\n",
    "        response = requests.get(url_issues, auth=HTTPBasicAuth(self.username, self.api_token))\n",
    "        if response.status_code == 200:\n",
    "            issues = response.json().get('issues', [])\n",
    "            return [issue['id'] for issue in issues]\n",
    "        return []\n",
    "\n",
    "    # New method to delete an issue given its ID\n",
    "    def delete_issue(self, issue_id):\n",
    "        url_delete = f\"https://{self.url}.atlassian.net/rest/api/3/issue/{issue_id}\"\n",
    "        response = requests.delete(url_delete, auth=HTTPBasicAuth(self.username, self.api_token))\n",
    "        return response.status_code == 204\n",
    "\n",
    "    # New method to delete all issues in a project\n",
    "    def delete_all_issues(self, project_key):\n",
    "        issue_ids = self.get_all_issue_ids(project_key)\n",
    "        for issue_id in issue_ids:\n",
    "            self.delete_issue(issue_id)\n",
    "        return f\"All issues in project {project_key} have been deleted.\"\n",
    "\n",
    "    # Recursive method to extract text from Jira's description content (which can be nested)\n",
    "    def extract_text(self, content):\n",
    "        texts = []\n",
    "        if isinstance(content, dict):\n",
    "            for key, value in content.items():\n",
    "                if key == 'text':\n",
    "                    texts.append(value)\n",
    "                elif isinstance(value, (list, dict)):\n",
    "                    texts.extend(self.extract_text(value))\n",
    "        elif isinstance(content, list):\n",
    "            for item in content:\n",
    "                texts.extend(self.extract_text(item))\n",
    "        return texts\n",
    "\n",
    "    # Static method to modify issue names by prefixing them with the issue type\n",
    "    @staticmethod\n",
    "    def modify_issue_names(all_issues_json):\n",
    "        for issue in all_issues_json:\n",
    "            issue_type = issue.get('type', '')\n",
    "            issue_name = issue.get('name', '')\n",
    "            issue['name'] = f\"{issue_type}: {issue_name}\"\n",
    "        return all_issues_json\n",
    "    # Static method to generate and add a unique key for each issue based on its name\n",
    "    @staticmethod\n",
    "    def add_key_field(all_issues_json):\n",
    "        for issue in all_issues_json:\n",
    "            name = issue['name']\n",
    "            hash_object = hashlib.sha256(name.encode())\n",
    "            key = int(hash_object.hexdigest(), 16) % (10**10)\n",
    "            issue['key'] = str(key)\n",
    "        return all_issues_json\n",
    "    \n",
    "    def create_new_issue(self, project_key, issue_name, issue_type, description, parent=None):\n",
    "        url_create_issue = \"https://{self.url}.atlassian.net/rest/api/3/issue\"\n",
    "        # Payload for creating an issue\n",
    "        payload = {\n",
    "            \"fields\": {\n",
    "                \"project\": {\n",
    "                    \"key\": project_key\n",
    "                },\n",
    "                \"summary\": issue_name,\n",
    "                \"issuetype\": {\n",
    "                    \"name\": issue_type\n",
    "                },\n",
    "                \"description\": {\n",
    "                    \"type\": \"doc\",\n",
    "                    \"version\": 1,\n",
    "                    \"content\": [\n",
    "                        {\n",
    "                            \"type\": \"paragraph\",\n",
    "                            \"content\": [\n",
    "                                {\n",
    "                                    \"text\": description,\n",
    "                                    \"type\": \"text\"\n",
    "                                }\n",
    "                            ]\n",
    "                        }\n",
    "                    ]\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "\n",
    "        # If a parent is provided and the issue type is not an Epic, set the parent field\n",
    "        if parent and issue_type.lower() != 'epic':\n",
    "            payload['fields']['parent'] = {\"key\": parent}\n",
    "            \n",
    "        print(f\"Payload for {issue_name}: {payload}\")  # Debugging print statement\n",
    "        response = requests.post(url_create_issue, auth=HTTPBasicAuth(self.username, self.api_token), json=payload)\n",
    "        print(f\"Response for {issue_name}: {response.json()}\")  # Debugging print statement\n",
    "        return response.json()\n",
    "\n",
    "    def create_issues_from_csv(self, csv_file_path, project_key):\n",
    "        df = pd.read_csv(csv_file_path)\n",
    "        created_issues = []\n",
    "        parent_mapping = {}  # To store parent issue keys\n",
    "\n",
    "        for _, row in df.iterrows():\n",
    "            issue_name = row['title']\n",
    "            description = row['description']\n",
    "            issue_type = row['type']\n",
    "            parent_name = row['parent']\n",
    "            skills = row['skills'] if row['skills'] else None\n",
    "            roles = row['roles']if row['roles'] else None\n",
    "            concat_description = f\"Description:\\n{description}\\nSkills_Requried:\\n{skills}\\nRoles:\\n{roles}\\n\"\n",
    "\n",
    "\n",
    "            # Determine the parent key for Stories and Subtasks\n",
    "            parent_key = None\n",
    "            if parent_name and issue_type.lower() != 'epic':\n",
    "                parent_key = parent_mapping.get(parent_name)\n",
    "                if not parent_key:\n",
    "                    print(f\"Parent key not found for {issue_name}. Parent Name: {parent_key}\")\n",
    "                    continue\n",
    "\n",
    "            # Create the issue and retrieve its key\n",
    "            response = self.create_new_issue(project_key, issue_name, issue_type, concat_description, parent_key)\n",
    "            if response and 'key' in response:\n",
    "                issue_key = response['key']\n",
    "                created_issues.append(issue_key)\n",
    "                # Store the key of Epics and Stories for their children to reference\n",
    "                if issue_type.lower() in ['epic', 'story']:\n",
    "                    parent_mapping[issue_name] = issue_key\n",
    "            else:\n",
    "                print(f\"Failed to create issue: {issue_name}\")\n",
    "\n",
    "        return created_issues\n",
    "\n",
    "class openai_issues:\n",
    "    def __init__(self, config):\n",
    "        self.api_key = config.openai_key\n",
    "        self.api_version = \"2023-07-01-preview\"\n",
    "        self.api_type = \"azure\"\n",
    "        self.api_base = config.open_ai_endpoint\n",
    "        self.engine = config.chat_engine\n",
    "        # Set up the global API configuration\n",
    "        openai.api_key = self.api_key\n",
    "        openai.api_version = self.api_version\n",
    "        openai.api_type = self.api_type\n",
    "        openai.api_base = self.api_base\n",
    "\n",
    "    def call_openai(self, messages, function_schema=None, function_call=None):\n",
    "        \n",
    "        kwargs = {\n",
    "        \"engine\": self.engine,\n",
    "        \"messages\": messages,\n",
    "        \"temperature\": 0.5\n",
    "        }\n",
    "        # Include function schema and call if they are provided\n",
    "        if function_schema is not None:\n",
    "            kwargs[\"functions\"] = function_schema\n",
    "        if function_call is not None:\n",
    "            kwargs[\"function_call\"] = function_call\n",
    "\n",
    "        response = openai.ChatCompletion.create(**kwargs)\n",
    "        \n",
    "        return response\n",
    "    \n",
    "    def generate_project_tasks_to_csv(self, project_description, output, schema):\n",
    "        persona = \"\"\"You are an Expert Technology Architect. Your job is to generate a CSV with columns that represent a Project in Jira, based on your expert knowledge of past projects of a similar type. The Columns of the CSV are [title,description,parent,type]. You must understand the project's requirements, organize the project in Epics, Stories and Subtasks. The title will contain the name of the issue, the description must be a detailed AGILE compliant Epic, Story or Subtask (50 words or less). Depending on the complexity of the user task, you may have one or multiple Stories / Subtasks under an Epic. Subtasks are part of Stories, and Stories are part of Epics. The final JSON (if converted to a Jira Project), should allow a team to build the project described by the user.\"\"\"\n",
    "    \n",
    "        # Make the API call to OpenAI\n",
    "        response = self.call_openai(\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": persona},\n",
    "                {\"role\": \"user\", \"content\": project_description}\n",
    "            ],\n",
    "            function_schema=schema,\n",
    "            function_call={\"name\": \"generate_project_JIRA\"},\n",
    "        )\n",
    "        \n",
    "        # Process the response and export to CSV\n",
    "        try:\n",
    "            dirty_class = response['choices'][0]['message']['function_call']['arguments']\n",
    "            task_data = json.loads(dirty_class).get(\"issues\")\n",
    "        except json.JSONDecodeError:\n",
    "            print(\"Failed to decode JSON from response\")\n",
    "            return\n",
    "        \n",
    "        df = pd.DataFrame(task_data)\n",
    "        df.loc[df['type'] == 'Epic', 'parent'] = None\n",
    "\n",
    "        df.to_csv(output, index=False, encoding='utf-8')\n",
    "        print(f\"CSV file '{output}' has been created in the current working directory.\")\n",
    "\n",
    "    def generate_description(self, project_context, current_title, issue_type, other_items_context, current_description):\n",
    "        # Define the length of the description based on issue type\n",
    "        length = 300 if issue_type == \"Epic\" else 200 if issue_type == \"Story\" else 100\n",
    "\n",
    "        # Construct the prompt with additional context\n",
    "        prompt = (\n",
    "            f\"Project Overview:\\n{project_context}\\n\\n\"\n",
    "            f\"Other Items in the Project:\\n{other_items_context}\\n\\n\"\n",
    "            f\"Write an Agile Compliant Description of length: {length} for a(n) {issue_type} titled: '{current_title}' - {current_description}\"\n",
    "            f\"If it's an Epic, you must assume the persona of a Product Owner, if it's a Story, assume a technical lead, and a developer writes the subtasks.\"\n",
    "        )\n",
    "        messages = [\n",
    "            {\"role\": \"system\", \"content\": \"You are a Master Solutions Architect, both a technical expert and a business leader.\"},\n",
    "            {\"role\": \"user\", \"content\": prompt}\n",
    "        ]\n",
    "        # Call OpenAI API\n",
    "        response = self.call_openai(\n",
    "            messages=messages\n",
    "        )\n",
    "        # Return the enhanced description extracted from the response\n",
    "        return response['choices'][0]['message']['content']\n",
    "    \n",
    "    def update_project_descriptions(self, csv_file_path, project_description, output_file_name):\n",
    "        project_context = project_description\n",
    "        \n",
    "        df = pd.read_csv(csv_file_path)\n",
    "        other_items_context = \"\\n\".join([f\"{row['type']}: {row['title']}\" for _, row in df.iterrows()])\n",
    "\n",
    "        for index, row in df.iterrows():\n",
    "            # Skipping the API request simulation, directly calling the method to generate descriptions\n",
    "            current_title = row['title']\n",
    "            issue_type = row['type']\n",
    "            current_description = row['description']\n",
    "            context_without_current = other_items_context.replace(f\"{issue_type}: {current_title}\\n\", \"\")\n",
    "            enhanced_description = self.generate_description(\n",
    "                project_context, current_title, issue_type, context_without_current, current_description\n",
    "            )\n",
    "            df.at[index, 'description'] = enhanced_description\n",
    "\n",
    "        df.to_csv(output_file_name, index=False)   \n",
    "\n",
    "    def generate_skills_for_issues(self, csv_file_name, schema):\n",
    "        df = pd.read_csv(csv_file_name)\n",
    "        df['skills'] = None\n",
    "        for index, row in df.iterrows():\n",
    "            title, description, issue_type = row['title'], row['description'], row['type']\n",
    "            parent = row['parent'] if pd.notna(row['parent']) else \"None\"\n",
    "            prompt = f\"Given a JIRA issue with the title '{title}', description '{description}', type '{issue_type}', and parent '{parent}', list the skills required to successfully accomplish this issue in the shape of a list.\"\n",
    "            messages = [\n",
    "                {\"role\": \"system\", \"content\": \"You are a Master Solutions Architect, both a technical expert and a business leader.\"},\n",
    "                {\"role\": \"user\", \"content\": f\"{prompt}\"}\n",
    "            ]\n",
    "            response = self.call_openai(\n",
    "                messages=messages,\n",
    "                function_schema=schema,\n",
    "                function_call={\"name\": \"generate_skills\"}\n",
    "            )\n",
    "            \n",
    "            try:\n",
    "                # Extract the skills from the API response and clean it up using regex\n",
    "                dirty_class = response['choices'][0]['message']['function_call']['arguments']\n",
    "                task_data = json.loads(dirty_class).get(\"skills\")\n",
    "            except json.JSONDecodeError:\n",
    "                print(\"Failed to decode JSON from response\")\n",
    "                continue  # Move on to the next iteration\n",
    "\n",
    "            df.at[index, 'skills'] = task_data\n",
    "\n",
    "        # Generate new filename with '_skills'\n",
    "        base_name, ext = os.path.splitext(csv_file_name)\n",
    "        new_filename = f\"{base_name}_skills{ext}\"\n",
    "        df.to_csv(new_filename, index=False)\n",
    "\n",
    "        return new_filename\n",
    "\n",
    "    def generate_roles_for_issues(self, csv_file_name, schema):\n",
    "        df = pd.read_csv(csv_file_name)\n",
    "        df['roles'] = None  # Add a new column for roles if it doesn't exist\n",
    "\n",
    "        for index, row in df.iterrows():\n",
    "            title = row['title']\n",
    "            description = row['description']\n",
    "            issue_type = row['type']\n",
    "            parent = row['parent'] if pd.notna(row['parent']) else \"None\"\n",
    "            \n",
    "            # Craft the prompt and call OpenAI API\n",
    "            response = self.call_openai(\n",
    "                messages=[\n",
    "                    {\"role\": \"system\", \"content\": \"You are a Master Solutions Architect, both a technical expert and a business leader.\"},\n",
    "                    {\"role\": \"user\", \"content\": f\"Given a JIRA issue with the title '{title}', description '{description}', type '{issue_type}', and parent '{parent}', list 5 employee roles in an IT company that could successfully deliver this Issue.\"}\n",
    "                ],\n",
    "                function_schema=schema,\n",
    "                function_call={\"name\": \"generate_roles\"}\n",
    "            )\n",
    "            \n",
    "            try:\n",
    "                # Extract the roles from the API response and clean it up using regex\n",
    "                dirty_class = response['choices'][0]['message']['function_call']['arguments']\n",
    "                task_data = json.loads(dirty_class).get(\"roles\")\n",
    "            except json.JSONDecodeError:\n",
    "                print(\"Failed to decode JSON from response\")\n",
    "                continue  # Move on to the next iteration\n",
    "\n",
    "            df.at[index, 'roles'] = task_data\n",
    "                # Generate new filename with '_roles'\n",
    "        base_name, ext = os.path.splitext(csv_file_name)\n",
    "        new_filename = f\"{base_name}_roles{ext}\"\n",
    "        df.to_csv(new_filename, index=False)\n",
    "        print(f\"roles and Skills CSV '{new_filename}' has been created in the current working directory.\")\n",
    "        return new_filename\n",
    "\n",
    "def main_jira_csv(root_name, project_name, project_description, config, csv_schema, skills_schema, role_schema):\n",
    "    # Create an instance of openai_jira with the provided configuration\n",
    "    jira_api = openai_issues(config)\n",
    "\n",
    "    # Define output CSV schema\n",
    "    output_schema = root_name\n",
    "    PROJECT = project_name # To be used if you want to upload csv into Jira as a Project\n",
    "    file_name = f\"{output_schema.replace('.csv', '')}_details.csv\"\n",
    "    \n",
    "    # Run the process\n",
    "    jira_api.generate_project_tasks_to_csv(project_description, output_schema, csv_schema)\n",
    "    jira_api.update_project_descriptions(output_schema, project_description, file_name)\n",
    "    skills_df = jira_api.generate_skills_for_issues(file_name, skills_schema)\n",
    "    final_csv = jira_api.generate_roles_for_issues(skills_df, role_schema)\n",
    "    \n",
    "    return final_csv\n",
    "\n",
    "class AzureDevOpsSDK:\n",
    "    def __init__(self, organization, project, personal_access_token):\n",
    "        self.organization = organization\n",
    "        self.project = project\n",
    "        self.credentials = BasicAuthentication('', personal_access_token)\n",
    "        self.connection = Connection(base_url=f'https://dev.azure.com/{self.organization}', \n",
    "                                     creds=self.credentials)\n",
    "\n",
    "    def create_work_item(self, work_item_type, title, description):\n",
    "        work_item_tracking_client = self.connection.clients.get_work_item_tracking_client()\n",
    "        patch_document = [\n",
    "            JsonPatchOperation(op=\"add\", path=\"/fields/System.Title\", value=title),\n",
    "            JsonPatchOperation(op=\"add\", path=\"/fields/System.Description\", value=description)\n",
    "        ]\n",
    "        work_item = work_item_tracking_client.create_work_item(document=patch_document, \n",
    "                                                               project=self.project, \n",
    "                                                               type=work_item_type)\n",
    "        return work_item\n",
    "\n",
    "    def link_parent(self, child_id, parent_id):\n",
    "        work_item_tracking_client = self.connection.clients.get_work_item_tracking_client()\n",
    "        patch_document = [\n",
    "            JsonPatchOperation(\n",
    "                op=\"add\",\n",
    "                path=\"/relations/-\",\n",
    "                value={\n",
    "                    \"rel\": \"System.LinkTypes.Hierarchy-Reverse\",\n",
    "                    \"url\": f\"https://dev.azure.com/{self.organization}/_apis/wit/workItems/{parent_id}\"\n",
    "                }\n",
    "            )\n",
    "        ]\n",
    "        work_item_tracking_client.update_work_item(document=patch_document, id=child_id)\n",
    "\n",
    "    def create_and_link_work_items(self, excel_file_path):\n",
    "        df = pd.read_excel(excel_file_path)\n",
    "        work_items_map = {}\n",
    "\n",
    "    # Create all work items first and store their IDs\n",
    "        for _, row in df.iterrows():\n",
    "            title = row['title']\n",
    "            description = row['description']\n",
    "            work_item_type = row['type']\n",
    "\n",
    "            work_item = self.create_work_item(work_item_type, title, description)\n",
    "            work_items_map[title] = work_item.id\n",
    "\n",
    "        # Link parent work items\n",
    "        for _, row in df.iterrows():\n",
    "            child_title = row['title']\n",
    "            parent_title = row.get('parent')\n",
    "            if pd.notna(parent_title) and parent_title in work_items_map and child_title != parent_title:\n",
    "                child_id = work_items_map[child_title]\n",
    "                parent_id = work_items_map[parent_title]\n",
    "                self.link_parent(child_id, parent_id)\n",
    "\n",
    "        return work_items_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV file './JiraPT/Output/test.csv' has been created in the current working directory.\n"
     ]
    }
   ],
   "source": [
    "# Define variables for the number of epics, stories, and subtasks\n",
    "num_epics = 1\n",
    "num_stories = 6\n",
    "num_subtasks = 0 # You can change this number as needed\n",
    "project_name = \"\"\n",
    "root_name = ''\n",
    "\n",
    "# Create the project description using f-strings\n",
    "project_description = f\"\"\" \n",
    "\n",
    "\n",
    "\"\"\"\n",
    "csv_schema = [\n",
    "    {\n",
    "        \"name\": \"generate_project_JIRA\",\n",
    "        \"description\": \"Generate a structured list of project tasks including Epics, Stories, and Subtasks based on the given project description. Each task should include 'title', 'description', 'parent', and 'type'. Epics have 'None' as the parent.\",\n",
    "        \"parameters\": {\n",
    "            \"type\": \"object\",\n",
    "            \"properties\": {\n",
    "                \"issues\": {\n",
    "                    \"type\": \"array\",\n",
    "                    \"items\": {\n",
    "                        \"type\": \"object\",\n",
    "                        \"properties\": {\n",
    "                            \"title\": {\"type\": \"string\"},\n",
    "                            \"description\": {\"type\": \"string\"},\n",
    "                            \"parent\": {\"type\": [\"string\", \"null\"]},\n",
    "                            \"type\": {\"type\": \"string\", \"enum\": [\"Epic\", \"Story\", \"Subtask\"]}\n",
    "                        },\n",
    "                        \"required\": [\"title\", \"description\", \"type\"]\n",
    "                    }\n",
    "                }\n",
    "            },\n",
    "            \"required\": [\"issues\"]\n",
    "        }\n",
    "    }\n",
    "]\n",
    "role_schema = [\n",
    "    {\n",
    "        \"name\": \"generate_roles\",\n",
    "        \"description\": \"Generates a list of roles in an IT Company that could successfully deliver the requirements of a given Jira Issue\",\n",
    "        \"parameters\": {\n",
    "            \"type\": \"object\",\n",
    "            \"properties\": {\n",
    "                \"roles\": {\n",
    "                    \"type\": \"array\",\n",
    "                    \"items\": {\"type\": \"string\"},\n",
    "                    \"description\": \"An array of roles in an IT Company that could successfully deliver the requirements of a given Jira Issue.\"\n",
    "                }\n",
    "            },\n",
    "            \"required\": [\"roles\"]\n",
    "        }\n",
    "    }\n",
    "]\n",
    "skills_schema = [\n",
    "    {\n",
    "        \"name\": \"generate_skills\",\n",
    "        \"description\": \"Generates a list of skills required to successfully accomplish a JIRA issue depending on its requirements.\",\n",
    "        \"parameters\": {\n",
    "            \"type\": \"object\",\n",
    "            \"properties\": {\n",
    "                \"skills\": {\n",
    "                    \"type\": \"array\",\n",
    "                    \"items\": {\"type\": \"string\"},\n",
    "                    \"description\": \"An array of skills an employee would require to succesfully complete the requirements outlined in a Jira issue.\"\n",
    "                }\n",
    "            },\n",
    "            \"required\": [\"skills\"]\n",
    "        }\n",
    "    }\n",
    "]\n",
    "\n",
    "final_df = main_jira_csv(root_name, project_name,project_description, Config(), csv_schema, skills_schema, role_schema)\n",
    "\n",
    "### IF you have a Jira server and API key, you may run the code below to upload:\n",
    "# Jira(Config()).create_issues_from_csv(final_df, \"project_name\")\n",
    "\n",
    "### IF you have a DevOps workspace and API key, you may run the code below to upload:\n",
    "organization = ''  # Replace with your organization name\n",
    "project = ''            # Replace with your project name\n",
    "personal_access_token = ''       # Replace with your PAT\n",
    "excel_file_path = ''  # Replace with the path to your Excel file\n",
    "\n",
    "azure_devops_sdk = AzureDevOpsSDK(organization, project, personal_access_token)\n",
    "work_items_map = azure_devops_sdk.create_and_link_work_items(excel_file_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
